# ğŸ› ï¸ DevOps Chatbot â€” Hybrid RAG + Realtime Web Search (Groq + Tavily + FAISS)

A powerful DevOps assistant chatbot that answers technical queries using both **static PDF docs** (FAISS) and **real-time web search** (Tavily), built with **LangChain**, **RAG** **Groq's LLaMA3**, **FastAPI**, and **Streamlit**.

---

## ğŸš€ Features

âœ… Real-time DevOps troubleshooting using **Tavily Search API**  
âœ… Vector-based search using **FAISS** and DevOps PDFs  
âœ… Answer generation using **Groqâ€™s LLaMA3** model  
âœ… FastAPI backend for flexible integration  
âœ… Streamlit frontend for easy web-based UI  
âœ… Dual mode hybrid retrieval (static + web)  
âœ… Prompt template & memory support  
âœ… Azure VM deployment-ready setup

---

## ğŸ“¦ Tech Stack

- **LangChain**
- **Groq LLaMA3 (via API)**
- **FAISS**
- **Tavily API** (for real-time web search)
- **FastAPI** (Backend API)
- **Streamlit** (Frontend UI)
- **Python 3.11**
- **Azure VM (B2s)** (Ubuntu 22.04)

---

## ğŸ“ Folder Structure

```bash
DevOps-Chatbot-Hybrid-RAG-Realtime/
â”œâ”€â”€ app.py                     # LangChain logic
â”œâ”€â”€ api.py                     # FastAPI routes
â”œâ”€â”€ streamlit_ui.py            # Streamlit frontend
â”œâ”€â”€ build_vectordb.py          # Converts PDFs to FAISS index
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ tavily_search.py       # Web search tool (Tavily)
â”œâ”€â”€ vectordb/
â”‚   â””â”€â”€ index.faiss            # FAISS vectorstore
â”œâ”€â”€ data/
â”‚   â””â”€â”€ *.pdf                  # DevOps documentation
â”œâ”€â”€ .env                       # API Keys
â”œâ”€â”€ requirements.txt
```

---

## ğŸ” Environment Variables (.env)

Create a `.env` file in the root directory and add:

```ini
TAVILY_API_KEY=your_tavily_api_key
GROQ_API_KEY=your_groq_api_key
```

---

## ğŸ§  How It Works

1. User enters a DevOps-related query
2. LangChain hybrid retriever fetches:
   - Relevant chunks from FAISS vectorstore (static)
   - Top results from the web using Tavily (dynamic)
3. Combined context is passed to Groqâ€™s LLaMA3 via prompt
4. Final response is shown via Streamlit UI or FastAPI response

---

## âš™ï¸ Setup Instructions

### ğŸ”§ 1. Clone & Install

```bash
git clone https://github.com/your-username/DevOps-Chatbot-Hybrid-RAG-Realtime.git
cd DevOps-Chatbot-Hybrid-RAG-Realtime
python3.11 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

### ğŸ“š 2. Add DevOps PDFs

Place your DevOps PDF files inside the `data/` folder.

### ğŸ§  3. Build FAISS Vector DB

```bash
python build_vectordb.py
```

### ğŸš€ 4. Run FastAPI Backend

```bash
uvicorn api:app --reload
```

### ğŸŒ 5. Run Streamlit Frontend

In another terminal:

```bash
streamlit run streamlit_app.py
```

## ğŸ”— Related Links

- ğŸ”— Tavily: [https://github.com/tavily/Tavily-python](https://github.com/tavily/Tavily-python)
- ğŸ”— LangChain: [https://www.langchain.com](https://www.langchain.com)
- ğŸ”— Groq: [https://console.groq.com](https://console.groq.com)

---

## ğŸ‘¨â€ğŸ’» Author

**Saim Qureshi**  
Final Year BSCS Student â€“ SMI University  
Vice President â€“ Science Society | Passionate about LLMs, RAG, and DevOps Automation

---

## ğŸ›¡ï¸ License

MIT License
